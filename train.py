import argparse
# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RprEZlauDgJMhuzX0XqvfS6B6KT-UYWt
"""

# !pip install torch-lr-finder

import torchvision.transforms as transforms
import glob
from torch.utils.data import DataLoader
import torchvision
import torch.nn as nn
import torch.optim as optim
import torch
import time
from PIL import Image

parser = argparse.ArgumentParser()
parser.add_argument('--epochs', type=int, default=20, help='number of epochs of training')
parser.add_argument('--train_root', type=str, default='/content/drive/MyDrive/Colab Notebooks/CNN_Project/datasets/train', help='directory of training set')
parser.add_argument('--valid_root', type=str, default='/content/drive/MyDrive/Colab Notebooks/CNN_Project/datasets/valid', help='directory of validation set')
parser.add_argument('--save_dir', type=str, default='/content/drive/MyDrive/Colab Notebooks/CNN_Project/saved_model', help='directory to save model')
opt = parser.parse_args()

class imgDataset():
    def __init__(self, root, transform, test=False):
          self.root = root
          self.test = test
          self.transform = transform
          self.basic_transform = transforms.ToTensor()
          self.pFiles = glob.glob(f"{root}/0/*.jpg")
          self.pLen = len(self.pFiles)
          self.nFiles = glob.glob(f"{root}/1/*.jpg")
          self.nLen = len(self.nFiles)
  
    def __len__(self):
          return self.pLen + self.nLen
    
    def __getitem__(self, index):
          if index < self.pLen:
              image = Image.open(self.pFiles[index])
              label = 0
          else:
              image = Image.open(self.nFiles[index - self.pLen])
              label = 1

          if self.test == False:
              image = self.transform(image)
          else:
              image = self.basic_transform(image)
          if self.test == False:
              return (image, label)
          else:
              return image

# train_root = '/content/drive/MyDrive/Colab Notebooks/CNN_Project/datasets/train'
trainset = imgDataset(opt.train_root,
                      transform = transforms.Compose([
                                                      transforms.ToTensor()
                      ]))
train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers = 4)

# valid_root = '/content/drive/MyDrive/Colab Notebooks/CNN_Project/datasets/valid'
validset = imgDataset(opt.valid_root,
                      transform = transforms.Compose([
                                                      transforms.ToTensor()
                      ]))
valid_loader = DataLoader(validset, batch_size=64, shuffle=True, num_workers=4)

model = torchvision.models.resnet101(pretrained=True)

num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2, bias=True)
model = model.cuda()

criterion = nn.CrossEntropyLoss()

optim = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)

def calc_accuracy(prediction, label):
    with torch.no_grad():
        _, pred2label = prediction.max(dim=1)
        same = (pred2label == label).float()
        accuracy = same.sum().item() / same.numel()
    return accuracy
# epochs = 20
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min')

start = time.time()
best_accuracy = 0.0
for epoch in range(opt.epochs):

    train_accuracy_list, valid_accuracy_list = [], []
    train_total_loss, valid_total_loss = 0.0, 0.0

    for _, (batch, label) in enumerate(train_loader):
        
        batch = batch.cuda()
        label = label.cuda()   

        prediction = model(batch)
        loss = criterion(prediction, label)

        optim.zero_grad()
        loss.backward()
        optim.step()

        train_accuracy_list.append(calc_accuracy(prediction, label))
        train_total_loss += loss.item()
    
    train_total_accuracy = sum(train_accuracy_list) / len(train_accuracy_list)

    with torch.no_grad():
        model.eval()
        for _, (batch, label) in enumerate(valid_loader):
            batch = batch.cuda()
            label = label.cuda()

            prediction = model(batch)
            loss = criterion(prediction, label)
            
            valid_accuracy_list.append(calc_accuracy(prediction, label))
            valid_total_loss += loss.item()
        
        valid_total_accuracy = sum(valid_accuracy_list) / len(valid_accuracy_list)

        if valid_total_accuracy > best_accuracy:
            best_accuracy = valid_total_accuracy
            best_model_state = model.state_dict()
            best_optim_state = optim.state_dict()
    scheduler.step(valid_total_loss)
    if epoch % (epochs // 10) == 0 or epoch == epochs - 1:
        print(f"""{time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())} || [{epoch}/{epochs}], train_loss = {train_total_loss:.4f}, train_accuracy = {train_total_accuracy:.2f}, valid_loss = {valid_total_loss:.4f}, valid_accuracy = {valid_total_accuracy:.2f}""")
        print("learning rate " + str(optim.param_groups[0]['lr']))
elapsed = time.time() - start
print(f"End of training, elapsed time : {elapsed // 60} min {elapsed % 60} sec.")

# savepath = '/content/drive/MyDrive/Colab Notebooks/CNN_Project/saved_model'
savepath = opt.save_dir
if best_model_state is not None and best_optim_state is not None:
    torch.save(best_model_state, f"{savepath}/model_state_dict.pt")
    torch.save(best_optim_state, f"{savepath}/optim_state_dict.pt")
    model.load_state_dict(best_model_state)
    torch.save(model, f"{savepath}/best_model.pt")
    print("Successfully saved.")